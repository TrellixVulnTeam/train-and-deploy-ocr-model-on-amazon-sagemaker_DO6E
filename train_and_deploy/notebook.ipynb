{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80d6ab47",
   "metadata": {},
   "source": [
    "# BYOC training for paddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df892e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#FROM paddlepaddle/paddle:2.0.0rc1-gpu-cuda10.1-cudnn7#\n",
      "FROM registry.baidubce.com/paddlepaddle/paddle:2.2.2-gpu-cuda10.2-cudnn7\n",
      "#ARG REGISTRY_URI\n",
      "#FROM ${REGISTRY_URI}/pytorch-training:1.3.1-cpu-py36-ubuntu16.04\n",
      "#FROM ${REGISTRY_URI}/pytorch-training:1.5.1-gpu-py36-cu101-ubuntu16.04\n",
      "#FROM ${REGISTRY_URI}/autogluon-training:0.2.1-gpu-py37-cu102-ubuntu18.04\n",
      "\n",
      "ENV LANG=en_US.utf8\n",
      "ENV LANG=C.UTF-8\n",
      "\n",
      "ENV PYTHONUNBUFFERED=TRUE\n",
      "ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      "ENV PATH=\"/opt/program:${PATH}\"\n",
      "#ENV LD_LIBRARY_PATH='/usr/local/cuda-10.1/targets/x86_64-linux/lib:${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}'\n",
      "\n",
      "##########################################################################################\n",
      "# SageMaker requirements\n",
      "##########################################################################################\n",
      "RUN pip3 install --upgrade pip\n",
      "\n",
      "## install flask\n",
      "#RUN pip3 install networkx==2.3 flask gevent gunicorn boto3 paddleocr>=2.0.1\n",
      "#todo: need to test the paddleocr version\n",
      "RUN pip3 install networkx==2.3 flask gevent gunicorn boto3 paddleocr==2.0.1\n",
      "\n",
      "#RUN pip3 install paddlepaddle-gpu==2.0rc1 -i https://opentuna.cn/pypi/web/simple\n",
      "RUN pip3 install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple\n",
      "\n",
      "#add folder\n",
      "#RUN git clone https://github.com/jackie930/PaddleOCR.git /opt/program/\n",
      "RUN git clone -b release/2.1 https://github.com/PaddlePaddle/PaddleOCR.git /opt/program/\n",
      "\n",
      "#download pretrained model for finetunine\n",
      "RUN mkdir /opt/program/pretrain/\n",
      "RUN cd /opt/program/pretrain/\n",
      "RUN wget -P /opt/program/pretrain/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_train.tar && tar -xf /opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train.tar -C /opt/program/pretrain/ && rm -rf /opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train.tar\n",
      "\n",
      "#download model for inference\n",
      "RUN mkdir /opt/program/inference/\n",
      "RUN cd /opt/program/inference/\n",
      "RUN wget -P /opt/program/inference/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_det_infer.tar && tar -xf /opt/program/inference/ch_ppocr_server_v2.0_det_infer.tar -C /opt/program/inference/ && rm -rf /opt/program/inference/ch_ppocr_server_v2.0_det_infer.tar\n",
      "RUN wget -P /opt/program/inference/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar && tar -xf /opt/program/inference/ch_ppocr_mobile_v2.0_cls_infer.tar -C /opt/program/inference/ && rm -rf /opt/program/inference/ch_ppocr_mobile_v2.0_cls_infer.tar\n",
      "#RUN wget -P /opt/program/inference/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_rec_infer.tar && tar -xf /opt/program/inference/ch_ppocr_server_v2.0_rec_infer.tar -C /opt/program/inference/ && rm -rf /opt/program/inference/ch_ppocr_server_v2.0_rec_infer.tar\n",
      "\n",
      "#RUN pip3.7 install -r /opt/program/requirements.txt -i https://opentuna.cn/pypi/web/simple\n",
      "\n",
      "### Install nginx notebook\n",
      "RUN apt-get -y update && apt-get install -y --no-install-recommends \\\n",
      "         wget \\\n",
      "         nginx \\\n",
      "         ca-certificates \\\n",
      "    && rm -rf /var/lib/apt/lists/*\n",
      "\n",
      "# forward request and error logs to docker log collector\n",
      "RUN ln -sf /dev/stdout /var/log/nginx/access.log\n",
      "RUN ln -sf /dev/stderr /var/log/nginx/error.log\n",
      "\n",
      "# Set up the program in the image\n",
      "COPY paddle/* /opt/program/\n",
      "RUN chmod +x /opt/program/serve\n",
      "WORKDIR /opt/program\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5312481e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set -e\n",
      "# This script shows how to build the Docker image and push it to ECR to be ready for use\n",
      "# by SageMaker.\n",
      "# here we need to specify aksk\n",
      "\n",
      "# The argument to this script is the image name. This will be used as the image on the local\n",
      "# machine and combined with the account and region to form the repository name for ECR.\n",
      "image=$1\n",
      "\n",
      "if [ \"$image\" == \"\" ]\n",
      "then\n",
      "    echo \"Use image name paddle\"\n",
      "    image=\"paddle\"\n",
      "fi\n",
      "Use image name paddle\n",
      "\n",
      "# Get the account number associated with the current IAM credentials\n",
      "account=$(aws sts get-caller-identity --query Account --output text)\n",
      "\n",
      "if [ $? -ne 0 ]\n",
      "then\n",
      "    exit 255\n",
      "fi\n",
      "\n",
      "# Get the region defined in the current configuration\n",
      "#if you only want to specify one region, use region, otherwise, use regions\n",
      "region=$(aws configure get region)\n",
      "\n",
      "if [[ $region =~ ^cn.* ]]\n",
      "then\n",
      "d\n",
      "elif [[ $region = \"ap-east-1\" ]]\n",
      "then\n",
      "    fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image}:latest\"\n",
      "    registry_id=\"871362719292\"\n",
      "    registry_uri=\"${registry_id}.dkr.ecr.${region}.amazonaws.com\"\n",
      "else\n",
      "    fullname=\"${account}.dkr.ecr.${region}.amazonaws.com/${image}:latest\"\n",
      "    registry_id=\"763104351884\"\n",
      "    registry_uri=\"${registry_id}.dkr.ecr.${region}.amazonaws.com\"\n",
      "fi\n",
      "\n",
      "echo ${fullname}\n",
      "847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle:latest\n",
      "\n",
      "# Get the login command from ECR and execute it directly\n",
      "$(aws ecr get-login --registry-ids ${account} --region ${region} --no-include-email)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "$(aws ecr get-login --registry-ids ${registry_id} --region ${region} --no-include-email)\n",
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n",
      "\n",
      "# If the repository doesn't exist in ECR, create it.\n",
      "aws ecr describe-repositories --repository-names \"${image}\" --region ${region} || aws ecr create-repository --repository-name \"${image}\" --region ${region}\n",
      "{\n",
      "    \"repositories\": [\n",
      "        {\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-west-2:847380964353:repository/paddle\",\n",
      "            \"registryId\": \"847380964353\",\n",
      "            \"repositoryName\": \"paddle\",\n",
      "            \"repositoryUri\": \"847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle\",\n",
      "            \"createdAt\": 1649226976.0,\n",
      "            \"imageTagMutability\": \"MUTABLE\",\n",
      "            \"imageScanningConfiguration\": {\n",
      "                \"scanOnPush\": false\n",
      "            },\n",
      "            \"encryptionConfiguration\": {\n",
      "                \"encryptionType\": \"AES256\"\n",
      "            }\n",
      "        }\n",
      "    ]\n",
      "}\n",
      "\n",
      "\n",
      "# Build the docker image, tag with full name and then push it to ECR\n",
      "#docker build -t ${image} -f Dockerfile . --build-arg REGISTRY_URI=${registry_uri}\n",
      "docker build -t ${image} -f Dockerfile . \n",
      "Sending build context to Docker daemon  579.6MB\n",
      "Step 1/23 : FROM registry.baidubce.com/paddlepaddle/paddle:2.2.2-gpu-cuda10.2-cudnn7\n",
      " ---> 833e3120ac8b\n",
      "Step 2/23 : ENV LANG=en_US.utf8\n",
      " ---> Using cache\n",
      " ---> 2b8bbccc7df6\n",
      "Step 3/23 : ENV LANG=C.UTF-8\n",
      " ---> Using cache\n",
      " ---> 6dd5bca7e0ea\n",
      "Step 4/23 : ENV PYTHONUNBUFFERED=TRUE\n",
      " ---> Using cache\n",
      " ---> 86ae3c239413\n",
      "Step 5/23 : ENV PYTHONDONTWRITEBYTECODE=TRUE\n",
      " ---> Using cache\n",
      " ---> e32defc6f2b7\n",
      "Step 6/23 : ENV PATH=\"/opt/program:${PATH}\"\n",
      " ---> Using cache\n",
      " ---> 8e557b866fd4\n",
      "Step 7/23 : RUN pip3 install --upgrade pip\n",
      " ---> Using cache\n",
      " ---> e7770eb46a49\n",
      "Step 8/23 : RUN pip3 install networkx==2.3 flask gevent gunicorn boto3 paddleocr==2.0.1\n",
      " ---> Using cache\n",
      " ---> 0f9e57787376\n",
      "Step 9/23 : RUN pip3 install paddlepaddle-gpu -i https://mirror.baidu.com/pypi/simple\n",
      " ---> Using cache\n",
      " ---> 9ba873911594\n",
      "Step 10/23 : RUN git clone -b release/2.1 https://github.com/PaddlePaddle/PaddleOCR.git /opt/program/\n",
      " ---> Using cache\n",
      " ---> c9ac6cc2f57f\n",
      "Step 11/23 : RUN mkdir /opt/program/pretrain/\n",
      " ---> Using cache\n",
      " ---> 103b2894c289\n",
      "Step 12/23 : RUN cd /opt/program/pretrain/\n",
      " ---> Using cache\n",
      " ---> 3e14a60edd1e\n",
      "Step 13/23 : RUN wget -P /opt/program/pretrain/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_rec_train.tar && tar -xf /opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train.tar -C /opt/program/pretrain/ && rm -rf /opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train.tar\n",
      " ---> Using cache\n",
      " ---> 350a44a78adc\n",
      "Step 14/23 : RUN mkdir /opt/program/inference/\n",
      " ---> Using cache\n",
      " ---> 1c7e976f99d1\n",
      "Step 15/23 : RUN cd /opt/program/inference/\n",
      " ---> Using cache\n",
      " ---> 789de167c67e\n",
      "Step 16/23 : RUN wget -P /opt/program/inference/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_server_v2.0_det_infer.tar && tar -xf /opt/program/inference/ch_ppocr_server_v2.0_det_infer.tar -C /opt/program/inference/ && rm -rf /opt/program/inference/ch_ppocr_server_v2.0_det_infer.tar\n",
      " ---> Using cache\n",
      " ---> 141709795cb4\n",
      "Step 17/23 : RUN wget -P /opt/program/inference/ https://paddleocr.bj.bcebos.com/dygraph_v2.0/ch/ch_ppocr_mobile_v2.0_cls_infer.tar && tar -xf /opt/program/inference/ch_ppocr_mobile_v2.0_cls_infer.tar -C /opt/program/inference/ && rm -rf /opt/program/inference/ch_ppocr_mobile_v2.0_cls_infer.tar\n",
      " ---> Using cache\n",
      " ---> 95f1959db5ec\n",
      "Step 18/23 : RUN apt-get -y update && apt-get install -y --no-install-recommends          wget          nginx          ca-certificates     && rm -rf /var/lib/apt/lists/*\n",
      " ---> Using cache\n",
      " ---> f491201f08ad\n",
      "Step 19/23 : RUN ln -sf /dev/stdout /var/log/nginx/access.log\n",
      " ---> Using cache\n",
      " ---> 596976c64056\n",
      "Step 20/23 : RUN ln -sf /dev/stderr /var/log/nginx/error.log\n",
      " ---> Using cache\n",
      " ---> 80f3f93047c3\n",
      "Step 21/23 : COPY paddle/* /opt/program/\n",
      " ---> 8afd9386e49d\n",
      "Step 22/23 : RUN chmod +x /opt/program/serve\n",
      " ---> Running in 82e1b7fce58d\n",
      "Removing intermediate container 82e1b7fce58d\n",
      " ---> cecca0d02d37\n",
      "Step 23/23 : WORKDIR /opt/program\n",
      " ---> Running in bdc899e4cc08\n",
      "Removing intermediate container bdc899e4cc08\n",
      " ---> 61a55d5f0b78\n",
      "Successfully built 61a55d5f0b78\n",
      "Successfully tagged paddle:latest\n",
      "docker tag ${image} ${fullname}\n",
      "docker push ${fullname}\n",
      "The push refers to repository [847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle]\n",
      "\n",
      "\u001b[1B4a674473: Preparing \n",
      "\u001b[1Bfe7a29b7: Preparing \n",
      "\u001b[1B0f045d58: Preparing \n",
      "\u001b[1B833006f5: Preparing \n",
      "\u001b[1Bacb363af: Preparing \n",
      "\u001b[1B0752fb0b: Preparing \n",
      "\u001b[1B9a17c125: Preparing \n",
      "\u001b[1B0bf9def9: Preparing \n",
      "\u001b[1Bac858fa0: Preparing \n",
      "\u001b[1B1a52ac0d: Preparing \n",
      "\u001b[1B5e834e81: Preparing \n",
      "\u001b[1B4ba8d876: Preparing \n",
      "\u001b[1Bdfd3954a: Preparing \n",
      "\u001b[1B74810d5a: Preparing \n",
      "\u001b[1Bed27354e: Preparing \n",
      "\u001b[1Bdb496db9: Preparing \n",
      "\u001b[12B752fb0b: Waiting g \n",
      "\u001b[1Bb9edd496: Preparing \n",
      "\u001b[13Ba17c125: Waiting g \n",
      "\u001b[13Bbf9def9: Waiting g \n",
      "\u001b[1Bd9b94457: Preparing \n",
      "\u001b[9B74810d5a: Waiting g \n",
      "\u001b[1B3e6a0620: Preparing \n",
      "\u001b[9Bdb496db9: Waiting g \n",
      "\u001b[16Ba52ac0d: Waiting g \n",
      "\u001b[1B66d91577: Preparing \n",
      "\u001b[6Bb0f44990: Waiting g \n",
      "\u001b[10B6db636d: Waiting g \n",
      "\u001b[1Bf973d417: Preparing \n",
      "\u001b[8B3e6a0620: Waiting g \n",
      "\u001b[12B6eb15cd: Waiting g \n",
      "\u001b[12B9b94457: Waiting g \n",
      "\u001b[1Bc36ae46b: Preparing \n",
      "\u001b[10B95aff2f: Waiting g \n",
      "\u001b[12B6552c9d: Waiting g \n",
      "\u001b[11B6d91577: Waiting g \n",
      "\u001b[1B31ec128b: Preparing \n",
      "\u001b[12B4e0b8f6: Waiting g \n",
      "\u001b[1B9e09cb2a: Preparing \n",
      "\u001b[13B7cac017: Waiting g \n",
      "\u001b[13B973d417: Waiting g \n",
      "\u001b[1B9802981c: Preparing \n",
      "\u001b[14B5b5fd58: Waiting g \n",
      "\u001b[1Bd0826bd0: Preparing \n",
      "\u001b[1Be534463e: Preparing \n",
      "\u001b[1B9c23949d: Preparing \n",
      "\u001b[1Baa143415: Preparing \n",
      "\u001b[18Ba60542f: Waiting g \n",
      "\u001b[1Beee58e2e: Preparing \n",
      "\u001b[19B107c840: Waiting g \n",
      "\u001b[13Be09cb2a: Waiting g \n",
      "\u001b[1B0fa70dc2: Preparing \n",
      "\u001b[14Bfeaa902: Waiting g \n",
      "\u001b[1Bc3c587b4: Preparing \n",
      "\u001b[15Bfd0c48f: Waiting g \n",
      "\u001b[20B1ec128b: Waiting g \n",
      "\u001b[16B802981c: Waiting g \n",
      "\u001b[24B1119efa: Waiting g \n",
      "\u001b[1B803d9a98: Preparing \n",
      "\u001b[17B0826bd0: Waiting g \n",
      "\u001b[1B70e4edfc: Preparing \n",
      "\u001b[18B534463e: Waiting g \n",
      "\u001b[13B7eeb7b7: Waiting g \n",
      "\u001b[1B74332e2e: Preparing \n",
      "\u001b[1B85b7bb16: Layer already exists 8kB\u001b[64A\u001b[2K\u001b[56A\u001b[2K\u001b[54A\u001b[2K\u001b[51A\u001b[2K\u001b[46A\u001b[2K\u001b[43A\u001b[2K\u001b[64A\u001b[2K\u001b[37A\u001b[2K\u001b[30A\u001b[2K\u001b[28A\u001b[2K\u001b[25A\u001b[2K\u001b[26A\u001b[2K\u001b[19A\u001b[2K\u001b[17A\u001b[2K\u001b[13A\u001b[2K\u001b[9A\u001b[2K\u001b[2A\u001b[2Klatest: digest: sha256:a74daf5295c44e224d27d87c0ff80e972b44812d84b108576e5e44efb100eac7 size: 13953\n"
     ]
    }
   ],
   "source": [
    "#first build docker\n",
    "!sh build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39bc639",
   "metadata": {},
   "source": [
    "## step1: upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bac055a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "#sess = sage.Session()\n",
    "sess = sage.LocalSession()\n",
    "\n",
    "WORK_DIRECTORY = \"./input/data\"\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"DEMO-paddle-byo\"\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67475398",
   "metadata": {},
   "source": [
    "## step2: local train (to debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f9e3ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating kirocbnzzz-algo-1-0rg0k ... \n",
      "Creating kirocbnzzz-algo-1-0rg0k ... done\n",
      "Attaching to kirocbnzzz-algo-1-0rg0k\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m Starting the training.\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m <<<< input files:  ['/opt/ml/input/data/training/rec_gt_train.txt', '/opt/ml/input/data/training/.ipynb_checkpoints', '/opt/ml/input/data/training/test', '/opt/ml/input/data/training/rec_gt_test.txt', '/opt/ml/input/data/training/train']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:03] root INFO: train.py with paddle 2.2.2 and device CUDAPlace(0)\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:03] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:03] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_test.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m W0413 05:47:03.395622     1 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.0, Runtime API Version: 10.2\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m W0413 05:47:03.400013     1 device_context.cc:465] device: 0, cuDNN Version: 7.6.\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:06] root INFO: load pretrained model from ['/opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train/best_accuracy']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:06] root INFO: train dataloader has 4 iters\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:06] root INFO: valid dataloader has 1 iters\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:06] root INFO: During the training process, after the 0th iteration, an evaluation is run every 2000 iterations\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:06] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:07] root INFO: epoch: [1/10], iter: 3, lr: 0.000996, loss: 12.525110, acc: 0.000000, norm_edit_dis: 0.572650, reader_cost: 0.05688 s, batch_cost: 0.14227 s, samples: 16, ips: 22.49197\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:07] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:07] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: epoch: [2/10], iter: 5, lr: 0.000990, loss: 11.321877, acc: 0.000000, norm_edit_dis: 0.681876, reader_cost: 0.04407 s, batch_cost: 0.07223 s, samples: 8, ips: 22.15275\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: epoch: [2/10], iter: 7, lr: 0.000981, loss: 9.077658, acc: 0.125000, norm_edit_dis: 0.814980, reader_cost: 0.00004 s, batch_cost: 0.02674 s, samples: 8, ips: 59.84254\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: epoch: [3/10], iter: 10, lr: 0.000962, loss: 6.913331, acc: 0.250000, norm_edit_dis: 0.853175, reader_cost: 0.04645 s, batch_cost: 0.08892 s, samples: 12, ips: 26.98904\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: epoch: [3/10], iter: 11, lr: 0.000954, loss: 6.235728, acc: 0.375000, norm_edit_dis: 0.867063, reader_cost: 0.00002 s, batch_cost: 0.01372 s, samples: 4, ips: 58.31882\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:08] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:09] root INFO: epoch: [4/10], iter: 15, lr: 0.000915, loss: 5.286814, acc: 0.500000, norm_edit_dis: 0.936069, reader_cost: 0.04177 s, batch_cost: 0.09644 s, samples: 16, ips: 33.18085\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:09] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:09] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: epoch: [5/10], iter: 19, lr: 0.000867, loss: 4.275720, acc: 0.625000, norm_edit_dis: 0.947287, reader_cost: 0.04998 s, batch_cost: 0.10454 s, samples: 16, ips: 30.61039\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: epoch: [6/10], iter: 20, lr: 0.000839, loss: 3.940687, acc: 0.750000, norm_edit_dis: 0.949760, reader_cost: 0.04035 s, batch_cost: 0.05563 s, samples: 4, ips: 14.38126\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: epoch: [6/10], iter: 23, lr: 0.000744, loss: 3.443928, acc: 0.750000, norm_edit_dis: 0.954167, reader_cost: 0.00008 s, batch_cost: 0.04092 s, samples: 12, ips: 58.64458\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:10] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:11] root INFO: epoch: [7/10], iter: 25, lr: 0.000673, loss: 3.133605, acc: 0.750000, norm_edit_dis: 0.958333, reader_cost: 0.04577 s, batch_cost: 0.07404 s, samples: 8, ips: 21.61110\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:11] root INFO: epoch: [7/10], iter: 27, lr: 0.000597, loss: 2.883654, acc: 0.750000, norm_edit_dis: 0.958333, reader_cost: 0.00004 s, batch_cost: 0.02683 s, samples: 8, ips: 59.62773\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:11] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:11] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:11] root INFO: epoch: [8/10], iter: 30, lr: 0.000480, loss: 2.577126, acc: 0.750000, norm_edit_dis: 0.958333, reader_cost: 0.04366 s, batch_cost: 0.08553 s, samples: 12, ips: 28.05956\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:12] root INFO: epoch: [8/10], iter: 31, lr: 0.000441, loss: 2.315307, acc: 0.750000, norm_edit_dis: 0.961310, reader_cost: 0.00002 s, batch_cost: 0.01336 s, samples: 4, ips: 59.87458\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:12] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:12] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:12] root INFO: epoch: [9/10], iter: 35, lr: 0.000291, loss: 2.262300, acc: 0.750000, norm_edit_dis: 0.961310, reader_cost: 0.04142 s, batch_cost: 0.09674 s, samples: 16, ips: 33.07790\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:12] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:12] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:13] root INFO: epoch: [10/10], iter: 39, lr: 0.000161, loss: 2.235988, acc: 0.750000, norm_edit_dis: 0.958333, reader_cost: 0.04397 s, batch_cost: 0.10100 s, samples: 16, ips: 31.68183\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:13] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:13] root INFO: best metric, acc: 0\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m Training complete.\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m [2022/04/13 05:47:15] root INFO: inference model is saved to /opt/ml/model/inference\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k |\u001b[0m convert model complete.\n",
      "\u001b[36mkirocbnzzz-algo-1-0rg0k exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "# local mode\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "image = \"847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle\"\n",
    "sess = sage.LocalSession()\n",
    "\n",
    "hyperparameters = {\"epoch_num\": 10,\n",
    "                  \"print_batch_step\":5,\n",
    "                  \"save_epoch_step\":30,\n",
    "                  'pretrained_model':'/opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train/best_accuracy'}\n",
    "\n",
    "train = sage.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    sagemaker_session=sess,\n",
    "    instance_type='local_gpu',\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "\n",
    "train.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fe577f",
   "metadata": {},
   "source": [
    "## optional: create training job for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c8b8099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-13 05:47:20 Starting - Starting the training job...\n",
      "2022-04-13 05:47:46 Starting - Preparing the instances for trainingProfilerReport-1649828840: InProgress\n",
      ".........\n",
      "2022-04-13 05:49:17 Downloading - Downloading input data\n",
      "2022-04-13 05:49:17 Training - Downloading the training image..................\n",
      "2022-04-13 05:52:13 Training - Training image download completed. Training in progress..\u001b[34mStarting the training.\u001b[0m\n",
      "\u001b[34m<<<< input files:  ['/opt/ml/input/data/training/.ipynb_checkpoints', '/opt/ml/input/data/training/rec_gt_train.txt', '/opt/ml/input/data/training/rec_gt_test.txt', '/opt/ml/input/data/training/train', '/opt/ml/input/data/training/test']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:19] root INFO: train.py with paddle 2.2.2 and device CUDAPlace(0)\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:19] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:19] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_test.txt']\u001b[0m\n",
      "\u001b[34mW0413 05:52:20.008754     1 device_context.cc:447] Please NOTE: device: 0, GPU Compute Capability: 7.0, Driver API Version: 11.4, Runtime API Version: 10.2\u001b[0m\n",
      "\u001b[34mW0413 05:52:20.148975     1 device_context.cc:465] device: 0, cuDNN Version: 7.6.\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:29] root INFO: load pretrained model from ['/opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train/best_accuracy']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:29] root INFO: train dataloader has 4 iters\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:29] root INFO: valid dataloader has 1 iters\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:29] root INFO: During the training process, after the 0th iteration, an evaluation is run every 2000 iterations\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:29] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:30] root INFO: epoch: [1/10], iter: 3, lr: 0.000996, loss: 12.501368, acc: 0.000000, norm_edit_dis: 0.602793, reader_cost: 0.08366 s, batch_cost: 0.18790 s, samples: 16, ips: 17.03044\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:30] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:30] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:31] root INFO: epoch: [2/10], iter: 5, lr: 0.000990, loss: 12.501368, acc: 0.000000, norm_edit_dis: 0.690690, reader_cost: 0.05919 s, batch_cost: 0.08886 s, samples: 8, ips: 18.00609\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:31] root INFO: epoch: [2/10], iter: 7, lr: 0.000981, loss: 8.977452, acc: 0.250000, norm_edit_dis: 0.783944, reader_cost: 0.00007 s, batch_cost: 0.02818 s, samples: 8, ips: 56.78280\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:31] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:31] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:32] root INFO: epoch: [3/10], iter: 10, lr: 0.000962, loss: 6.651520, acc: 0.500000, norm_edit_dis: 0.873016, reader_cost: 0.06921 s, batch_cost: 0.11183 s, samples: 12, ips: 21.46033\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:32] root INFO: epoch: [3/10], iter: 11, lr: 0.000954, loss: 6.207094, acc: 0.500000, norm_edit_dis: 0.876984, reader_cost: 0.00003 s, batch_cost: 0.01377 s, samples: 4, ips: 58.09486\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:32] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:32] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/iter_epoch_3\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:32] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:32] root INFO: epoch: [4/10], iter: 15, lr: 0.000915, loss: 4.772032, acc: 0.500000, norm_edit_dis: 0.895685, reader_cost: 0.05244 s, batch_cost: 0.11599 s, samples: 16, ips: 27.58875\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:33] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:33] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:33] root INFO: epoch: [5/10], iter: 19, lr: 0.000867, loss: 4.772032, acc: 0.500000, norm_edit_dis: 0.895685, reader_cost: 0.06461 s, batch_cost: 0.12367 s, samples: 16, ips: 25.87536\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:33] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:33] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:34] root INFO: epoch: [6/10], iter: 20, lr: 0.000839, loss: 4.533867, acc: 0.500000, norm_edit_dis: 0.901786, reader_cost: 0.06583 s, batch_cost: 0.08191 s, samples: 4, ips: 9.76699\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:34] root INFO: epoch: [6/10], iter: 23, lr: 0.000744, loss: 4.297304, acc: 0.500000, norm_edit_dis: 0.915476, reader_cost: 0.00010 s, batch_cost: 0.04199 s, samples: 12, ips: 57.15544\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:34] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:34] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/iter_epoch_6\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:34] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:35] root INFO: epoch: [7/10], iter: 25, lr: 0.000673, loss: 3.671285, acc: 0.625000, norm_edit_dis: 0.926694, reader_cost: 0.05726 s, batch_cost: 0.09035 s, samples: 8, ips: 17.70807\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:35] root INFO: epoch: [7/10], iter: 27, lr: 0.000597, loss: 2.885858, acc: 0.750000, norm_edit_dis: 0.949653, reader_cost: 0.00006 s, batch_cost: 0.02741 s, samples: 8, ips: 58.36741\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:35] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:35] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:36] root INFO: epoch: [8/10], iter: 30, lr: 0.000480, loss: 2.849493, acc: 0.750000, norm_edit_dis: 0.956597, reader_cost: 0.05727 s, batch_cost: 0.10109 s, samples: 12, ips: 23.74113\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:36] root INFO: epoch: [8/10], iter: 31, lr: 0.000441, loss: 2.649257, acc: 0.750000, norm_edit_dis: 0.949653, reader_cost: 0.00003 s, batch_cost: 0.01734 s, samples: 4, ips: 46.13663\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:36] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:36] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:36] root INFO: epoch: [9/10], iter: 35, lr: 0.000291, loss: 2.455866, acc: 0.750000, norm_edit_dis: 0.956597, reader_cost: 0.05687 s, batch_cost: 0.11786 s, samples: 16, ips: 27.15162\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:36] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:37] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/iter_epoch_9\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:37] root INFO: Initialize indexs of datasets:['/opt/ml/input/data/training/rec_gt_train.txt']\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:37] root INFO: epoch: [10/10], iter: 39, lr: 0.000161, loss: 2.455866, acc: 0.750000, norm_edit_dis: 0.958333, reader_cost: 0.06623 s, batch_cost: 0.12552 s, samples: 16, ips: 25.49435\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:37] root INFO: save model in /opt/ml/model/rec_chinese_lite_v2.0/latest\u001b[0m\n",
      "\u001b[34m[2022/04/13 05:52:37] root INFO: best metric, acc: 0\u001b[0m\n",
      "\u001b[34mTraining complete.\u001b[0m\n",
      "\n",
      "2022-04-13 05:52:48 Uploading - Uploading generated training model\u001b[34m[2022/04/13 05:52:40] root INFO: inference model is saved to /opt/ml/model/inference\u001b[0m\n",
      "\u001b[34mconvert model complete.\u001b[0m\n",
      "\n",
      "2022-04-13 05:53:05 Completed - Training job completed\n",
      "ProfilerReport-1649828840: NoIssuesFound\n",
      "Training seconds: 243\n",
      "Billable seconds: 243\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "image = \"847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle\"\n",
    "\n",
    "sess = sage.Session()\n",
    "hyperparameters = {\"epoch_num\": 10,\n",
    "                  \"print_batch_step\":5,\n",
    "                  \"save_epoch_step\":3,\n",
    "                  'pretrained_model':'/opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train/best_accuracy'}\n",
    "\n",
    "train = sage.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    sagemaker_session=sess,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "\n",
    "train.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88fb746",
   "metadata": {},
   "source": [
    " # Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d41be8be",
   "metadata": {},
   "source": [
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the topic mixture representing a given document.This section involves several steps,\n",
    "Create Model \n",
    "- Create model for the training outputCreate Endpoint Configuration \n",
    "- Create a configuration defining an endpoint.Create Endpoint \n",
    "- Use the configuration to create an inference endpoint.Perform Inference \n",
    "- Perform inference on some input data using the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a69014",
   "metadata": {},
   "source": [
    "## deploy model\n",
    "we now create a SageMaker Model from the training output. Using the model we can create an Endpoint Configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "dee23a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle-v0\n",
      "arn:aws:sagemaker:us-west-2:847380964353:model/paddle-v0\n",
      "CPU times: user 132 ms, sys: 16 ms, total: 148 ms\n",
      "Wall time: 490 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "model_name=\"paddle-v0\"\n",
    "print(model_name)\n",
    "\n",
    "info = sage.describe_training_job(TrainingJobName=\"paddle-2022-04-13-05-47-20-163\")\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "#model_data = train.model_data\n",
    "#print(model_data)\n",
    "\n",
    "hosting_image = \"847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle\"\n",
    "primary_container = {\n",
    "    'Image': hosting_image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7efad1",
   "metadata": {},
   "source": [
    "## Create Endpoint Configuration\n",
    "#At launch, we will support configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, customers create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way.In addition, the endpoint configuration describes the instance type required for model deployment, and at launch will describe the autoscaling configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42021579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint configuration name: paddle-epc--2022-04-13-06-03-09\n",
      "Endpoint configuration arn:  arn:aws:sagemaker:us-west-2:847380964353:endpoint-config/paddle-epc--2022-04-13-06-03-09\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "import time \n",
    "\n",
    "job_name_prefix = \"paddle\"\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.g4dn.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dca2aba",
   "metadata": {},
   "source": [
    "##  Create Endpoint\n",
    "Lastly, the customer creates the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40f21180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name: paddle-ep--2022-04-13-06-03-10\n",
      "EndpointArn = arn:aws:sagemaker:us-west-2:847380964353:endpoint/paddle-ep--2022-04-13-06-03-10\n",
      "CPU times: user 6.31 ms, sys: 0 ns, total: 6.31 ms\n",
      "Wall time: 247 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sage.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149df863",
   "metadata": {},
   "source": [
    " If you see the message, Endpoint creation ended with ```EndpointStatus = InService``` then congratulations! You now have a functioning inference endpoint. You can confirm the endpoint configuration and status by navigating to the \"Endpoints\" tab in the AWS SageMaker console.We will finally create a runtime object from which we can invoke the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c3822",
   "metadata": {},
   "source": [
    "#  Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e90853c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"bucket\": \"bot-ocr-test-bucket\", \"image_uri\": \"1.png\", \"content_type\": \"application/json\"}\n",
      "{'label': ['婴巴马', '别男', '糖肯尼亚', '出些·1961年4日', '华盛顿特区宜宾法尼亚', '大道1600号白宫', '公E与盛', '12345196108047&9③'], 'confidences': [12.665797233581543, 10.436362266540527, 12.495158195495605, 13.70422077178955, 16.082889556884766, 14.658669471740723, 9.809164047241211, 15.068533897399902], 'bbox': [[[32.0, 64.0], [241.0, 56.0], [243.0, 92.0], [33.0, 100.0]], [[34.0, 138.0], [179.0, 138.0], [179.0, 173.0], [34.0, 173.0]], [[250.0, 135.0], [435.0, 134.0], [436.0, 165.0], [250.0, 166.0]], [[32.0, 212.0], [462.0, 209.0], [462.0, 246.0], [33.0, 249.0]], [[28.0, 293.0], [505.0, 291.0], [506.0, 332.0], [28.0, 334.0]], [[131.0, 365.0], [396.0, 362.0], [396.0, 396.0], [131.0, 398.0]], [[30.0, 494.0], [246.0, 494.0], [246.0, 528.0], [30.0, 528.0]], [[309.0, 496.0], [791.0, 492.0], [791.0, 526.0], [309.0, 530.0]]], 'shape': [588, 940, 3]}\n",
      "CPU times: user 29.7 ms, sys: 0 ns, total: 29.7 ms\n",
      "Wall time: 756 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from sagemaker.session import Session\n",
    "\n",
    "config = Config(\n",
    "    read_timeout=120,\n",
    "    retries={\n",
    "        'max_attempts': 0\n",
    "    }\n",
    ")\n",
    "\n",
    "from boto3.session import Session\n",
    "import json\n",
    "\n",
    "#bucket = 'datalab2022'\n",
    "#image_uri = '1.jpg'\n",
    "bucket = 'bot-ocr-test-bucket'\n",
    "image_uri = '1.png'\n",
    "test_data = {\n",
    "    'bucket' : bucket,\n",
    "    'image_uri' : image_uri,\n",
    "    'content_type': \"application/json\",\n",
    "}\n",
    "payload = json.dumps(test_data)\n",
    "print(payload)\n",
    "\n",
    "sagemaker_runtime_client = boto3.client('sagemaker-runtime', config=config)\n",
    "session = Session(sagemaker_runtime_client)\n",
    "\n",
    "#     runtime = session.client(\"runtime.sagemaker\",config=config)\n",
    "response = sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload)\n",
    "\n",
    "result = json.loads(response[\"Body\"].read())\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51e2e1",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "22da9f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paddle-ep--2022-04-13-05-54-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': '842e4591-7ecf-42bb-950e-8d9cb273a478',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '842e4591-7ecf-42bb-950e-8d9cb273a478',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Wed, 13 Apr 2022 06:02:27 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(endpoint_name)\n",
    "sage.delete_endpoint(EndpointName=endpoint_name)\n",
    "sage.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sage.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1df7a98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'paddle-ep--2022-04-13-05-54-10'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f566e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
