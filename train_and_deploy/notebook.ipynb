{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fa486fb",
   "metadata": {},
   "source": [
    "# BYOC training for paddleOCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fe725f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat Dockerfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d207d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#first build docker\n",
    "!sh build_and_push.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6232dd3",
   "metadata": {},
   "source": [
    "## step1: upload data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04febc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker as sage\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "#sess = sage.Session()\n",
    "sess = sage.LocalSession()\n",
    "\n",
    "WORK_DIRECTORY = \"./input/data\"\n",
    "\n",
    "# S3 prefix\n",
    "prefix = \"DEMO-paddle-byo\"\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "data_location = sess.upload_data(WORK_DIRECTORY, key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c73f0b",
   "metadata": {},
   "source": [
    "## step2: local train (to debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482f8e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# local mode\n",
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/paddle\".format(account, region)\n",
    "sess = sage.LocalSession()\n",
    "\n",
    "hyperparameters = {\"epoch_num\": 10,\n",
    "                  \"print_batch_step\":5,\n",
    "                  \"save_epoch_step\":30,\n",
    "                  'pretrained_model':'/opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train/best_accuracy'}\n",
    "\n",
    "train = sage.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    sagemaker_session=sess,\n",
    "    instance_type='local_gpu',\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "\n",
    "train.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a79852",
   "metadata": {},
   "source": [
    "## optional: create training job for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a73b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "account = sess.boto_session.client(\"sts\").get_caller_identity()[\"Account\"]\n",
    "region = sess.boto_session.region_name\n",
    "image = \"{}.dkr.ecr.{}.amazonaws.com/paddle\".format(account, region)\n",
    "\n",
    "sess = sage.Session()\n",
    "hyperparameters = {\"epoch_num\": 10,\n",
    "                  \"print_batch_step\":5,\n",
    "                  \"save_epoch_step\":3,\n",
    "                  'pretrained_model':'/opt/program/pretrain/ch_ppocr_mobile_v2.0_rec_train/best_accuracy'}\n",
    "\n",
    "train = sage.estimator.Estimator(\n",
    "    image,\n",
    "    role,\n",
    "    instance_count = 1,\n",
    "    sagemaker_session=sess,\n",
    "    instance_type='ml.p3.2xlarge',\n",
    "    hyperparameters=hyperparameters,\n",
    ")\n",
    "\n",
    "\n",
    "train.fit(data_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b6f694",
   "metadata": {},
   "source": [
    " # Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7036ba50",
   "metadata": {},
   "source": [
    "A trained model does nothing on its own. We now want to use the model to perform inference. For this example, that means predicting the topic mixture representing a given document.This section involves several steps,\n",
    "Create Model \n",
    "- Create model for the training outputCreate Endpoint Configuration \n",
    "- Create a configuration defining an endpoint.Create Endpoint \n",
    "- Use the configuration to create an inference endpoint.Perform Inference \n",
    "- Perform inference on some input data using the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff7a42e",
   "metadata": {},
   "source": [
    "## deploy model\n",
    "we now create a SageMaker Model from the training output. Using the model we can create an Endpoint Configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d56d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import boto3\n",
    "from time import gmtime, strftime\n",
    "\n",
    "sage = boto3.Session().client(service_name='sagemaker') \n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "role = get_execution_role()\n",
    "\n",
    "model_name=\"paddle-v0\"\n",
    "print(model_name)\n",
    "\n",
    "info = sage.describe_training_job(TrainingJobName=train.latest_training_job.name)\n",
    "model_data = info['ModelArtifacts']['S3ModelArtifacts']\n",
    "\n",
    "#model_data = train.model_data\n",
    "#print(model_data)\n",
    "\n",
    "# hosting_image = \"847380964353.dkr.ecr.us-west-2.amazonaws.com/paddle\"\n",
    "primary_container = {\n",
    "    'Image': image,\n",
    "    'ModelDataUrl': model_data,\n",
    "}\n",
    "\n",
    "create_model_response = sage.create_model(\n",
    "    ModelName = model_name,\n",
    "    ExecutionRoleArn = role,\n",
    "    PrimaryContainer = primary_container)\n",
    "\n",
    "print(create_model_response['ModelArn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91430bd1",
   "metadata": {},
   "source": [
    "## Create Endpoint Configuration\n",
    "#At launch, we will support configuring REST endpoints in hosting with multiple models, e.g. for A/B testing purposes. In order to support this, customers create an endpoint configuration, that describes the distribution of traffic across the models, whether split, shadowed, or sampled in some way.In addition, the endpoint configuration describes the instance type required for model deployment, and at launch will describe the autoscaling configuration.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d294e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "import time \n",
    "\n",
    "job_name_prefix = \"paddle\"\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_config_name = job_name_prefix + '-epc-' + timestamp\n",
    "endpoint_config_response = sage.create_endpoint_config(\n",
    "    EndpointConfigName = endpoint_config_name,\n",
    "    ProductionVariants=[{\n",
    "        'InstanceType':'ml.g4dn.xlarge',\n",
    "        'InitialInstanceCount':1,\n",
    "        'ModelName':model_name,\n",
    "        'VariantName':'AllTraffic'}])\n",
    "\n",
    "print('Endpoint configuration name: {}'.format(endpoint_config_name))\n",
    "print('Endpoint configuration arn:  {}'.format(endpoint_config_response['EndpointConfigArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2857b085",
   "metadata": {},
   "source": [
    "##  Create Endpoint\n",
    "Lastly, the customer creates the endpoint that serves up the model, through specifying the name and configuration defined above. The end result is an endpoint that can be validated and incorporated into production applications. This takes 9-11 minutes to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4c0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import time\n",
    "\n",
    "timestamp = time.strftime('-%Y-%m-%d-%H-%M-%S', time.gmtime())\n",
    "endpoint_name = job_name_prefix + '-ep-' + timestamp\n",
    "print('Endpoint name: {}'.format(endpoint_name))\n",
    "\n",
    "endpoint_params = {\n",
    "    'EndpointName': endpoint_name,\n",
    "    'EndpointConfigName': endpoint_config_name,\n",
    "}\n",
    "endpoint_response = sage.create_endpoint(**endpoint_params)\n",
    "print('EndpointArn = {}'.format(endpoint_response['EndpointArn']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f98901",
   "metadata": {},
   "source": [
    " If you see the message, Endpoint creation ended with ```EndpointStatus = InService``` then congratulations! You now have a functioning inference endpoint. You can confirm the endpoint configuration and status by navigating to the \"Endpoints\" tab in the AWS SageMaker console.We will finally create a runtime object from which we can invoke the endpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a53dada",
   "metadata": {},
   "source": [
    "#  Perform Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c7ad69",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "from sagemaker.session import Session\n",
    "\n",
    "config = Config(\n",
    "    read_timeout=120,\n",
    "    retries={\n",
    "        'max_attempts': 0\n",
    "    }\n",
    ")\n",
    "\n",
    "from boto3.session import Session\n",
    "import json\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "image_uri = 'DEMO-paddle-byo/test/1.jpg'\n",
    "test_data = {\n",
    "    'bucket' : bucket,\n",
    "    'image_uri' : image_uri,\n",
    "    'content_type': \"application/json\",\n",
    "}\n",
    "payload = json.dumps(test_data)\n",
    "print(payload)\n",
    "\n",
    "sagemaker_runtime_client = boto3.client('sagemaker-runtime', config=config)\n",
    "session = Session(sagemaker_runtime_client)\n",
    "\n",
    "#     runtime = session.client(\"runtime.sagemaker\",config=config)\n",
    "response = sagemaker_runtime_client.invoke_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    ContentType=\"application/json\",\n",
    "    Body=payload)\n",
    "\n",
    "result = json.loads(response[\"Body\"].read())\n",
    "print (result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f82e07",
   "metadata": {},
   "source": [
    "# Clean up\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62066ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(endpoint_name)\n",
    "sage.delete_endpoint(EndpointName=endpoint_name)\n",
    "sage.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "sage.delete_model(ModelName=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2dc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7814f94c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
